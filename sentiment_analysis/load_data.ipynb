{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c600597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install neo4j transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bfefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import secret\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# ————— Load model & tokenizer —————\n",
    "model_name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# ————— Neo4j HTTP setup —————\n",
    "auth = HTTPBasicAuth(\"neo4j\", secret.password)\n",
    "\n",
    "batch_size = 1000\n",
    "skip = 0\n",
    "\n",
    "while True:\n",
    "    # Fetch a batch of tweets\n",
    "    batch_query = {\n",
    "        \"statements\": [\n",
    "            {\n",
    "                \"statement\": f\"\"\"\n",
    "                    MATCH (t:Tweet)\n",
    "                    RETURN id(t) AS node_id, t.text AS text, t.id AS tweet_id\n",
    "                    SKIP {skip} LIMIT {batch_size}\n",
    "                \"\"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(secret.url, json=batch_query, auth=auth)\n",
    "    data = response.json()\n",
    "    tweets = [\n",
    "        {\"node_id\": row[\"row\"][0], \"text\": row[\"row\"][1], \"tweet_id\": row[\"row\"][2]}\n",
    "        for row in data[\"results\"][0][\"data\"]\n",
    "    ]\n",
    "\n",
    "    if not tweets:\n",
    "        # No more tweets to process\n",
    "        break\n",
    "\n",
    "    # Show progress bar, no other prints\n",
    "    for tweet in tqdm(tweets, desc=f\"Processing batch {skip // batch_size + 1}\", unit=\"tweet\"):\n",
    "        node_id = tweet[\"node_id\"]\n",
    "        tweet_long_id = tweet[\"tweet_id\"]\n",
    "        raw_text = tweet[\"text\"]\n",
    "        text = preprocess(raw_text)\n",
    "\n",
    "        inputs  = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        scores = outputs.logits[0].softmax(dim=0).numpy()\n",
    "        neg, neu, pos = float(scores[0]), float(scores[1]), float(scores[2])\n",
    "\n",
    "        sentiment_score = round(pos - neg, 4)\n",
    "\n",
    "        max_idx = np.argmax([neg, neu, pos])\n",
    "        label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "        sentiment_label = label_map[max_idx]\n",
    "\n",
    "        update_query = {\n",
    "            \"statements\": [\n",
    "                {\n",
    "                    \"statement\": \"\"\"\n",
    "                        MATCH (t:Tweet) WHERE id(t) = $node_id\n",
    "                        SET t.positive = $pos,\n",
    "                            t.neutral = $neu,\n",
    "                            t.negative = $neg,\n",
    "                            t.sentiment_score = $score,\n",
    "                            t.sentiment_label = $label,\n",
    "                            t.id = $tweet_id\n",
    "                    \"\"\",\n",
    "                    \"parameters\": {\n",
    "                        \"node_id\": node_id,\n",
    "                        \"pos\": pos,\n",
    "                        \"neu\": neu,\n",
    "                        \"neg\": neg,\n",
    "                        \"score\": sentiment_score,\n",
    "                        \"label\": sentiment_label,\n",
    "                        \"tweet_id\": tweet_long_id\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        update_response = requests.post(secret.url, json=update_query, auth=auth)\n",
    "        if update_response.status_code != 200:\n",
    "            # Optionally handle or log errors here without printing\n",
    "            pass\n",
    "\n",
    "    skip += batch_size #runs code\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "o2IAB1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
